# LLM/VLM NPC 비용 및 성능

## 지연 목표
- 채팅 응답: 800ms 이내 평균, 2초 이내 P95.
- 행동 결정: 300ms 이내 평균.
- 서버 처리 예산: 리듀서/검증 50~100ms 내.

## 토큰 예산
- 턴당 상한: 500-800 토큰.
- 세션당 상한: 5K-8K 토큰.
- 컨텍스트 비율: 시스템/정책 20%, 월드 스냅샷 30%, 대화 50% 이내.

## 캐싱 전략
- 재사용 규칙: 반복 질문과 일반 안내는 캐시.
- 요약 트리거: 8턴 이상 누적 시 요약.
- 세션 캐시: 같은 NPC/플레이어 쌍의 최근 응답 캐시.
- 정책 캐시: 금칙/정책 프롬프트는 고정 템플릿으로 재사용.

## 모델 전략
- 티어링: 경량 모델 우선, 고난도는 상위 모델.
- 폴백: 안전 응답 + 규칙 기반 대화.
- 라우팅 기준: 쿼리 길이/의도/행동 요청 여부/쿨다운 상태.

## 부하 테스트
- NPC 동시성: 1만 동시 대화 기준.
- 예산 알림: 일일 80% 도달 시 경보.
- 큐잉: 대기열 길이/평균 대기시간 모니터링.

## 실행 경로 최적화
- 짧은 응답은 경량 모델 우선.
- 고비용 요청은 단계적 요약 후 실행.
- 대화 세션 종료 시 요약 저장.
- 사전 필터: 금칙/권한 위반은 모델 호출 전에 컷.

## 서버 리듀서 비용
- 리듀서 호출 빈도 제한.
- NPC 행동 트리거는 배치 처리.
- TradeOrder/Quest 생성은 일괄 처리 후 커밋.

## 세부 설계 (BitCraft 참고)

### 주기 정렬
- NPC AI 에이전트(예: 300초)와 LLM 호출 주기를 분리해, 상태 갱신은 배치로 처리.
- trade_order 재생성은 NPC 주기 시점에만 수행해 중복 호출 방지.

### 캐시 계층
- 동일 질문/안내는 NPC별 응답 캐시 + 요약 캐시(최근 5~10턴).
- 컨텍스트 스냅샷(위치/바이옴/관계치)은 서버에서 생성해 LLM 입력 토큰 절감.
- 월드 스냅샷은 타일/청크 단위 캐시로 공유.

### 비용 절감 전략
- 경량 모델: 안내/수락/거절/간단 상호작용 처리.
- 상위 모델: 퀘스트 생성/복합 판단 시에만 사용, 결과는 요약 저장.
- 리다이렉트: 행동이 불필요한 문의는 FAQ/정적 응답으로 전환.

### 성능 가드레일
- 응답 길이 상한: 120~200 토큰(안내), 300~500 토큰(퀘스트).
- 시간 초과: P95 초과 시 규칙 기반 응답으로 강제 폴백.
- 동시성 제한: 플레이어당 동시 대화 1개, NPC당 동시 요청 제한.
